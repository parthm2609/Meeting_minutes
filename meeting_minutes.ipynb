{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this product is to use the Audio to generate meeting minutes, including actions.\n",
        "\n",
        "For this project, you can either use the available datasets, or you can record something of your own!"
      ],
      "metadata": {
        "id": "EhGJZNPtMFg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 openai"
      ],
      "metadata": {
        "id": "PXV7lWSmMMyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "# from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
      ],
      "metadata": {
        "id": "9VHNs0xOQiiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "ksVtPk2c6UO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_MODEL = \"openai/whisper-medium\"\n",
        "speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(AUDIO_MODEL, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True)\n",
        "speech_model.to('cuda')\n",
        "processor = AutoProcessor.from_pretrained(AUDIO_MODEL)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=speech_model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch.float16,\n",
        "    device='cuda',\n",
        "    chunk_length_s=30\n",
        ")"
      ],
      "metadata": {
        "id": "eOud8SJG3I5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "audio_filename = \"/content/drive/MyDrive/LLM/denver_extract.mp3\""
      ],
      "metadata": {
        "id": "ztvEddMn3jdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "r-lq69WM4PlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(audio_filename)"
      ],
      "metadata": {
        "id": "-JNfLM054clo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = result[\"text\"]\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "_jLBvQdo4iV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, takeaways and action items with owners, in markdown.\"\n",
        "user_prompt = f\"Below is an extract transcript of a Denver council meeting. Please write minutes in markdown, including a summary with attendees, location and date; discussion points; takeaways; and action items with owners.\\n{transcription}\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "  ]\n"
      ],
      "metadata": {
        "id": "SXQyyYzv5l1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_compute_dtype = torch.bfloat16,\n",
        "    bnb_4bit_quant_type = \"nf4\"\n",
        ")"
      ],
      "metadata": {
        "id": "vgqVd8Cu55zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "inputs = tokenizer.apply_chat_template(messages, return_tensors = \"pt\").to(\"cuda\")\n",
        "streamer = TextStreamer(tokenizer)\n",
        "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n",
        "outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)"
      ],
      "metadata": {
        "id": "m7JiEnx36NBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response = tokenizer.decode(outputs[0])\n",
        "prompt_length = inputs.shape[1]\n",
        "\n",
        "generated_tokens = outputs[0][prompt_length:]\n",
        "\n",
        "\n",
        "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "36m5g0Ho64tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "id": "PklcGokT-pZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3a-ECWRd-sA4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}